[
  {
    "id": "cleanup.py_cleanup_old_uploads",
    "filename": "cleanup.py",
    "function_name": "cleanup_old_uploads",
    "text": "## Function: cleanup_old_uploads (cleanup.py)\n\n```python\ndef cleanup_old_uploads():\n    logger.info(\"Starting cleanup of old uploads...\")\n    print(\"Current working dir:\", os.getcwd())\n    print(\"BASE_DIR:\", BASE_DIR)\n    print(\"UPLOAD_FOLDER:\", UPLOAD_FOLDER)\n    print(\"RMS_ANALYSIS_FOLDER:\", RMS_ANALYSIS_FOLDER)\n    now = time.time()\n    db = SessionLocal()\n    try:\n        # Delete old audio files tracked in DB and remove their DB records\n        old_tracks = db.query(Track).all()\n        print(f\"Found {len(old_tracks)} tracks in DB\")\n        for track in old_tracks:\n            file_path_str = track.file_path\n            if not file_path_str:\n                print(\"Track has no file_path, skipping\")\n                continue\n\n            file_path = Path(file_path_str)\n            print(f\"Checking track file path: {file_path}\")\n\n            if file_path.exists():\n                file_age = now - file_path.stat().st_mtime\n                print(f\"File age (seconds): {file_age}\")\n                if file_age > MAX_FILE_AGE_SECONDS:\n                    try:\n                        file_path.unlink()\n                        logger.info(f\"Deleted old track file: {file_path}\")\n\n                        # Also delete associated RMS file if exists\n                        rms_filename = f\"{file_path.name}_rms.json\"\n                        rms_file_path = RMS_ANALYSIS_FOLDER / rms_filename\n                        if rms_file_path.exists():\n                            try:\n                                rms_file_path.unlink()\n                                logger.info(f\"Deleted RMS file: {rms_file_path}\")\n                            except Exception as e:\n                                logger.error(f\"Error deleting RMS file {rms_file_path}: {e}\")\n\n                        # Delete related analysis_results\n                        deleted_count = db.query(AnalysisResult).filter(AnalysisResult.track_id == track.id).delete()\n                        logger.info(f\"Deleted {deleted_count} analysis results for track {track.id}\")\n\n                        # Instead of deleting Track, just clear the file_path\n                        track.file_path = None\n                        db.add(track)  # mark for update\n\n                    except Exception as e:\n                        logger.error(f\"Error deleting files or DB record for {file_path}: {e}\")\n                else:\n                    print(f\"File not old enough to delete: {file_path}\")\n            else:\n                print(f\"File path does not exist: {file_path}\")\n\n        db.commit()  # Commit deletions after all done\n\n        # Delete all old orphan files in the UPLOAD_FOLDER (files not tracked in DB)\n        print(\"Checking for orphan files in upload folder...\")\n        for file_path in UPLOAD_FOLDER.iterdir():\n            if file_path.is_file():\n                file_age = now - file_path.stat().st_mtime\n                print(f\"Orphan file {file_path}, age: {file_age}\")\n                if file_age > MAX_FILE_AGE_SECONDS:\n                    try:\n                        file_path.unlink()\n                        logger.info(f\"Deleted orphan upload file: {file_path}\")\n                    except Exception as e:\n                        logger.error(f\"Error deleting orphan upload file {file_path}: {e}\")\n\n        # Delete all old RMS JSON files in the RMS_ANALYSIS_FOLDER (cleanup orphan RMS files)\n        print(\"Checking for orphan RMS JSON files...\")\n        for rms_file in RMS_ANALYSIS_FOLDER.glob(\"*.json\"):\n            file_age = now - rms_file.stat().st_mtime\n            print(f\"RMS file {rms_file}, age: {file_age}\")\n            if file_age > MAX_FILE_AGE_SECONDS:\n                try:\n                    rms_file.unlink()\n                    logger.info(f\"Deleted orphan RMS JSON file: {rms_file}\")\n                except Exception as e:\n                    logger.error(f\"Error deleting orphan RMS file {rms_file}: {e}\")\n\n    finally:\n        db.close()\n    logger.info(\"Cleanup finished.\")\n```\n"
  },
  {
    "id": "utils.py_sanitize_input",
    "filename": "utils.py",
    "function_name": "sanitize_input",
    "text": "## Function: sanitize_input (utils.py)\n\n```python\ndef sanitize_input(input_str: str) -> str:\n    \"\"\"Sanitize string: trim, normalize whitespace, limit length.\"\"\"\n    if not isinstance(input_str, str):\n        return \"\"\n    return re.sub(r\"\\s+\", \" \", input_str.strip())[:100]\n```\n"
  },
  {
    "id": "utils.py_sanitize_user_question",
    "filename": "utils.py",
    "function_name": "sanitize_user_question",
    "text": "## Function: sanitize_user_question (utils.py)\n\n```python\ndef sanitize_user_question(text: str) -> str:\n    if not isinstance(text, str):\n        return \"\"\n    # Remove unwanted characters (allow common punctuation)\n    cleaned = re.sub(r\"[^\\w\\s.,!?@&$()\\-+=:;\\'\\\"/]\", \"\", text.strip())\n    # Limit length to 400 chars (adjust as needed)\n    cleaned = cleaned[:400]\n    # Escape HTML entities to prevent injection\n    return html.escape(cleaned)\n```\n"
  },
  {
    "id": "utils.py_normalize_session_name",
    "filename": "utils.py",
    "function_name": "normalize_session_name",
    "text": "## Function: normalize_session_name (utils.py)\n\n```python\ndef normalize_session_name(name: str) -> str:\n    \"\"\"\n    Sanitize user-provided session name:\n    - Trim whitespace\n    - Allow only letters, numbers, spaces, dashes, and underscores\n    - Truncate to 60 characters\n    - Escape HTML for safety in prompts/UI\n    \"\"\"\n    if not isinstance(name, str):\n        return \"\"\n    name = name.strip()\n    name = re.sub(r\"[^\\w\\s\\-]\", \"\", name)  # Keep alphanumeric, space, dash, underscore\n    name = name[:60]\n    return html.escape(name)\n```\n"
  },
  {
    "id": "utils.py_safe_track_name",
    "filename": "utils.py",
    "function_name": "safe_track_name",
    "text": "## Function: safe_track_name (utils.py)\n\n```python\ndef safe_track_name(name, fallback_filename):\n    name = name.strip() if name else \"\"\n    return name if name and name.lower() != \"string\" else os.path.splitext(fallback_filename)[0]\n```\n"
  },
  {
    "id": "utils.py_normalize_type",
    "filename": "utils.py",
    "function_name": "normalize_type",
    "text": "## Function: normalize_type (utils.py)\n\n```python\ndef normalize_type(input_str: str) -> str:\n    \"\"\"Sanitize and validate track type.\"\"\"\n    val = sanitize_input(input_str).lower()\n    return val if val in ALLOWED_TYPES else \"mixdown\"\n```\n"
  },
  {
    "id": "utils.py_normalize_profile",
    "filename": "utils.py",
    "function_name": "normalize_profile",
    "text": "## Function: normalize_profile (utils.py)\n\n```python\ndef normalize_profile(input_str: str) -> str:\n    \"\"\"Sanitize and validate feedback profile.\"\"\"\n    val = sanitize_input(input_str).lower()\n    return val if val in ALLOWED_PROFILES else \"simple\"\n```\n"
  },
  {
    "id": "utils.py_normalize_genre",
    "filename": "utils.py",
    "function_name": "normalize_genre",
    "text": "## Function: normalize_genre (utils.py)\n\n```python\ndef normalize_genre(input_str: str) -> str:\n    \"\"\"Sanitize and validate genre.\"\"\"\n    val = sanitize_input(input_str).lower()\n    return val if val in ALLOWED_GENRES else \"electronic\"\n```\n"
  },
  {
    "id": "utils.py_normalize_subgenre",
    "filename": "utils.py",
    "function_name": "normalize_subgenre",
    "text": "## Function: normalize_subgenre (utils.py)\n\n```python\ndef normalize_subgenre(sub: str) -> str:\n    \"\"\"\n    Sanitize and normalize a user-provided subgenre string.\n\n    - Strips leading/trailing whitespace\n    - Limits to ASCII letters, digits, spaces, dashes, ampersands, and apostrophes\n    - Truncates to 50 characters\n    - Escapes HTML for safe injection into prompts\n    - Converts to title case (e.g., 'neo-soul' → 'Neo-Soul')\n    \"\"\"\n    if not isinstance(sub, str):\n        return \"\"\n\n    # Basic cleanup\n    sub = sub.strip()\n\n    # Remove unwanted characters (but allow dashes, ampersands, apostrophes)\n    sub = re.sub(r\"[^a-zA-Z0-9 &\\-']\", \"\", sub)\n\n    # Truncate to prevent abuse or overflow\n    sub = sub[:50]\n\n    # Convert to title case\n    sub = sub.title()\n\n    # Escape for prompt safety\n    return html.escape(sub)\n```\n"
  },
  {
    "id": "gpt_utils.py_generate_feedback_prompt",
    "filename": "gpt_utils.py",
    "function_name": "generate_feedback_prompt",
    "text": "## Function: generate_feedback_prompt (gpt_utils.py)\n\n```python\ndef generate_feedback_prompt(genre: str, subgenre: str, type: str, analysis_data: dict, feedback_profile: str, ref_analysis_data: dict = None) -> str:\n    \"\"\"\n            Constructs a detailed AI prompt combining role context, communication style,\n            audio analysis data, reference track data (optional), and formatting instructions.\n\n            Parameters:\n                genre (str): Music genre, normalized.\n                subgenre (str): Music subgenre, normalized.\n                type (str): Feedback type ('mixdown', 'mastering', 'master').\n                analysis_data (dict): Audio analysis metrics of the submitted track.\n                feedback_profile (str): Desired feedback complexity ('simple', 'detailed', 'pro').\n                ref_analysis_data (dict, optional): Reference track analysis for comparison.\n\n            Returns:\n                str: Formatted prompt string ready to be sent to the AI model.\n            \"\"\"\n\n    type = normalize_type(type)\n    if type not in ROLE_CONTEXTS:\n        raise ValueError(f\"Unknown type: {type}\")\n    genre = normalize_genre(genre)\n    if genre not in ALLOWED_GENRES:\n        raise ValueError(f\"Unknown genre: {genre}\")\n    subgenre = normalize_subgenre(subgenre)\n    feedback_profile = normalize_profile(feedback_profile)\n    if feedback_profile not in PROFILE_GUIDANCE:\n        raise ValueError(f\"Unknown feedback_profile: {feedback_profile}\")\n\n    context = (\n            REFERENCE_TRACK_INSTRUCTION + \"\\n\\n\" + ROLE_CONTEXTS[type].format(\n        genre=html.escape(genre),\n        subgenre=html.escape(subgenre)\n    )\n    )\n    communication_style = PROFILE_GUIDANCE[feedback_profile]\n\n    # Add reference track data section if available\n    ref_section = \"\"\n    if ref_analysis_data:\n        ref_section = f\"\"\"\n    ### Reference Track Analysis (for comparison)\n    - Peak: {ref_analysis_data['peak_db']} dB\n    - RMS Peak: {ref_analysis_data['rms_db_peak']} dB\n    - LUFS: {ref_analysis_data['lufs']}\n    - Transients: {ref_analysis_data['transient_description']}\n    - Spectral balance note: {ref_analysis_data['spectral_balance_description']}\n    - Dynamic range: {ref_analysis_data['dynamic_range']}\n    - Stereo width: {ref_analysis_data['stereo_width']}\n    - Bass profile: {ref_analysis_data.get('low_end_description', '')}\n    \"\"\"\n\n    peak_warning = \"\"\n    if analysis_data.get(\"peak_issue_explanation\"):\n        peak_warning = f\"\\n⚠️ Peak warning: {analysis_data['peak_issue_explanation']}\\n\"\n\n    format_rule = FORMAT_RULES.get(feedback_profile, FORMAT_RULES[\"detailed\"])\n\n    example_output = EXAMPLE_OUTPUTS.get(feedback_profile, \"\")\n\n    # Final assembly\n    return f\"\"\"\n### Context\n{context}\n\n- **Respect the genre context**. F.e. only suggest reducing bass if clearly excessive relative to the genre’s typical sound.\n\n### Communication Style\n{communication_style}\n\n### Track Analysis Data\n- Peak: {analysis_data['peak_db']} dB\n- RMS Peak: {analysis_data['rms_db_peak']} dB\n- LUFS: {analysis_data['lufs']}\n- Avg Transient Strength: {analysis_data['avg_transient_strength']}\n- Max Transient Strength: {analysis_data['max_transient_strength']}\n- Transients: {analysis_data['transient_description']}\nIf low-end is flagged as strong but typical for the genre, do NOT treat it as a problem unless masking, muddiness, or translation concerns are clearly implied.\n- Spectral balance note: {analysis_data['spectral_balance_description']}\n- Dynamic range: {analysis_data['dynamic_range']}\n- Stereo width: {analysis_data['stereo_width']}\n- Bass profile: {analysis_data.get('low_end_description', '')}\n  (Genre: {genre} — please consider if the low-end level suits this genre’s typical sound.)\n\n### REFERENCE TRACK\nHere is analysis data for the reference track. Use this data to inform your feedback and compare where appropriate.\n{ref_section}\n\n{peak_warning}\n\n### Reasoning Step\nUse the reference track when provided as a benchmark to guide specific suggestions even when not typical for genre etc..\nBefore writing the bullet points, briefly reflect on what stands out from the analysis data.\nWrite 2–3 sentences summarizing key characteristics or concerns about the mix (this part will not be shown to the user).\n\n### Bullet Point Feedback\nNow return exactly 2–3 bullet points.\n\n{format_rule.strip()}\n\n⚠️ Do **not** include a title, greeting, summary, or closing line.\n\n{example_output}\n\"\"\".strip()\n```\n"
  },
  {
    "id": "gpt_utils.py_generate_feedback_response",
    "filename": "gpt_utils.py",
    "function_name": "generate_feedback_response",
    "text": "## Function: generate_feedback_response (gpt_utils.py)\n\n```python\ndef generate_feedback_response(prompt: str) -> str:\n    \"\"\"\n        Sends a prompt string to the AI model and returns the generated feedback text.\n\n        Parameters:\n            prompt (str): The fully constructed prompt containing context, instructions, and analysis data.\n\n        Returns:\n            str: The AI-generated feedback text, stripped of leading/trailing whitespace.\n        \"\"\"\n    response = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    # response = client.chat.completions.create(\n    #     model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n    #     messages=[{\"role\": \"user\", \"content\": prompt}]\n    # )\n    return response.choices[0].message.content.strip()\n```\n"
  },
  {
    "id": "gpt_utils.py_generate_followup_response",
    "filename": "gpt_utils.py",
    "function_name": "generate_followup_response",
    "text": "## Function: generate_followup_response (gpt_utils.py)\n\n```python\ndef generate_followup_response(analysis_text: str, feedback_text: str, user_question: str, thread_summary: str = \"\") -> str:\n    \"\"\"\n        Builds a follow-up prompt incorporating prior analysis, feedback, user question,\n        and optionally a summary of the follow-up conversation thread, then sends it to the AI.\n\n        Parameters:\n            analysis_text (str): Text description of the audio analysis.\n            feedback_text (str): Previous AI feedback given to the user.\n            user_question (str): The user's follow-up question.\n            thread_summary (str, optional): Summary of previous follow-up messages for context.\n\n        Returns:\n            str: AI-generated answer to the follow-up question.\n        \"\"\"\n    prompt = build_followup_prompt(analysis_text, feedback_text, user_question, thread_summary)\n    return generate_feedback_response(prompt)\n```\n"
  },
  {
    "id": "gpt_utils.py_build_followup_prompt",
    "filename": "gpt_utils.py",
    "function_name": "build_followup_prompt",
    "text": "## Function: build_followup_prompt (gpt_utils.py)\n\n```python\ndef build_followup_prompt(\n    analysis_text: str,\n    feedback_text: str,\n    user_question: str,\n    thread_summary: str = \"\",\n    ref_analysis_data: dict = None,   # NEW parameter\n) -> str:\n    \"\"\"\n        Constructs a detailed prompt for AI follow-up feedback based on prior analysis,\n        previous feedback, the user’s follow-up question, optional conversation summary,\n        and optionally reference track analysis data.\n\n        Parameters:\n            analysis_text (str): Text description of the audio analysis.\n            feedback_text (str): Previous AI feedback text.\n            user_question (str): User’s follow-up question.\n            thread_summary (str, optional): Summary of prior follow-up conversation for context.\n            ref_analysis_data (dict, optional): Reference track analysis for comparison.\n\n        Returns:\n            str: A formatted prompt string ready for submission to the AI model.\n        \"\"\"\n\n    # Clean and escape user question\n    user_question = re.sub(r\"[^\\w\\s.,!?@&$()\\-+=:;\\'\\\"/]\", \"\", user_question.strip())[:400]\n    user_question = html.escape(user_question)\n\n    ref_section = \"\"\n    if ref_analysis_data and isinstance(ref_analysis_data, dict):\n        ref_section = f\"\"\"\n        ### Reference Track Analysis (for comparison)\n        - Peak: {ref_analysis_data.get('peak_db', 'N/A')} dB\n        - RMS Peak: {ref_analysis_data.get('rms_db_peak', 'N/A')} dB\n        - LUFS: {ref_analysis_data.get('lufs', 'N/A')}\n        - Transients: {ref_analysis_data.get('transient_description', 'N/A')}\n        - Spectral balance note: {ref_analysis_data.get('spectral_balance_description', 'N/A')}\n        - Dynamic range: {ref_analysis_data.get('dynamic_range', 'N/A')}\n        - Stereo width: {ref_analysis_data.get('stereo_width', 'N/A')}\n        - Bass profile: {ref_analysis_data.get('low_end_description', '')}\n        \"\"\"\n    else:\n        print(\"Warning: ref_analysis_data missing or invalid:\", ref_analysis_data)\n\n    return f\"\"\"\nYou are a helpful and professional **audio engineer assistant**.\n\n{\"### Summary of Previous Conversation\\n\" + thread_summary + \"\\n\" if thread_summary else \"\"}\n\n### Track Analysis\n{analysis_text}\n\n{ref_section}\n\n### Prior Feedback\n{feedback_text}\n\n### User's Follow-Up Question\n\"{user_question}\"\n\n### Instructions\n- Use the analysis, feedback, and summary above as context.\n- Do **not** repeat the full analysis or feedback.\n- Answer the follow-up clearly and concisely.\n- Stay on topic and be technically helpful.\n- If the question is vague, use the existing context to infer intent.\n\nRespond below:\n\"\"\"\n```\n"
  },
  {
    "id": "audio_analysis.py_detect_key",
    "filename": "audio_analysis.py",
    "function_name": "detect_key",
    "text": "## Function: detect_key (audio_analysis.py)\n\n```python\ndef detect_key(y, sr):\n    chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\n    chroma_mean = np.mean(chroma, axis=1)\n\n    major_profile = np.array([6.35, 2.23, 3.48, 2.33, 4.38, 4.09,\n                              2.52, 5.19, 2.39, 3.66, 2.29, 2.88])\n    minor_profile = np.array([6.33, 2.68, 3.52, 5.38, 2.60, 3.53,\n                              2.54, 4.75, 3.98, 2.69, 3.34, 3.17])\n\n    best_corr = -1\n    best_key = \"\"\n    note_names = ['C', 'C#', 'D', 'D#', 'E', 'F',\n                  'F#', 'G', 'G#', 'A', 'A#', 'B']\n    for i in range(12):\n        corr_major = np.corrcoef(np.roll(major_profile, i), chroma_mean)[0, 1]\n        corr_minor = np.corrcoef(np.roll(minor_profile, i), chroma_mean)[0, 1]\n\n        if corr_major > best_corr:\n            best_corr = corr_major\n            best_key = f\"{note_names[i]} Major\"\n        if corr_minor > best_corr:\n            best_corr = corr_minor\n            best_key = f\"{note_names[i]} minor\"\n\n    return best_key\n```\n"
  },
  {
    "id": "audio_analysis.py_compute_band_energies",
    "filename": "audio_analysis.py",
    "function_name": "compute_band_energies",
    "text": "## Function: compute_band_energies (audio_analysis.py)\n\n```python\ndef compute_band_energies(S, freqs):\n    bands = {\n        \"sub\": (20, 60),\n        \"low\": (60, 250),\n        \"low-mid\": (250, 500),\n        \"mid\": (500, 2000),\n        \"high-mid\": (2000, 4000),\n        \"high\": (4000, 8000),\n        \"air\": (8000, 16000)\n    }\n\n    total_energy = np.sum(S)\n    band_energies = {}\n\n    for band, (low, high) in bands.items():\n        mask = (freqs >= low) & (freqs < high)\n        band_energy = np.sum(S[mask])\n        band_energies[band] = round(float(band_energy / (total_energy + 1e-9)), 4)\n\n    return band_energies\n```\n"
  },
  {
    "id": "audio_analysis.py_describe_low_end_profile",
    "filename": "audio_analysis.py",
    "function_name": "describe_low_end_profile",
    "text": "## Function: describe_low_end_profile (audio_analysis.py)\n\n```python\ndef describe_low_end_profile(ratio: float, genre: str = None) -> str:\n    genre = (genre or \"\").lower()\n\n    bass_driven = {\"electronic\", \"hiphop\", \"rnb\"}\n    balanced = {\"pop\", \"rock\", \"indie\", \"reggae\", \"funk\", \"soul\", \"classic\"}\n    less_bassy = {\"punk\", \"metal\", \"jazz\", \"country\", \"folk\"}\n\n    if genre in bass_driven:\n        if ratio < 0.08:\n            return f\"Low-end is light for {genre}. Consider boosting the bass or sub for fullness.\"\n        elif ratio < 0.28:\n            return f\"Low-end feels balanced for bass-driven music.\"\n        elif ratio < 0.45:\n            return f\"Low-end is elevated — still genre-typical. No changes needed unless masking is audible.\"\n        else:\n            return f\"Low-end is very strong — double-check clarity in the sub region.\"\n\n    elif genre in balanced:\n        if ratio < 0.05:\n            return f\"Low-end is light — may sound thin or underpowered for {genre}.\"\n        elif ratio < 0.20:\n            return f\"Low-end feels appropriate and balanced for this style.\"\n        elif ratio < 0.35:\n            return f\"Low-end is strong — possibly a stylistic choice, but check for mud or masking.\"\n        else:\n            return f\"Low-end is very heavy — could overwhelm mids or make the mix feel boomy.\"\n\n    elif genre in less_bassy:\n        if ratio < 0.03:\n            return f\"Low-end is very light — likely appropriate for {genre}.\"\n        elif ratio < 0.12:\n            return f\"Low-end feels balanced and controlled for this genre.\"\n        elif ratio < 0.25:\n            return f\"Low-end is on the heavier side — may still work, but ensure it doesn't obscure midrange clarity.\"\n        else:\n            return f\"Low-end is unusually strong for {genre} — might overpower vocals or acoustic instruments.\"\n\n    else:\n        # Fallback for unknown genres\n        if ratio < 0.05:\n            return \"Low-end is very light — might feel thin unless intentional.\"\n        elif ratio < 0.15:\n            return \"Low-end is on the light side, but may be fine for minimal or acoustic styles.\"\n        elif ratio < 0.30:\n            return \"Low-end appears balanced — acceptable for many genres.\"\n        elif ratio < 0.45:\n            return \"Low-end is strong — stylistic, but check for muddiness.\"\n        else:\n            return \"Low-end is very dominant — could overwhelm mids or cause translation issues.\"\n```\n"
  },
  {
    "id": "audio_analysis.py_describe_spectral_balance",
    "filename": "audio_analysis.py",
    "function_name": "describe_spectral_balance",
    "text": "## Function: describe_spectral_balance (audio_analysis.py)\n\n```python\ndef describe_spectral_balance(band_energies: dict, genre: str = \"electronic\") -> str:\n    # Collapse to simple groups\n    sub = band_energies.get(\"sub\", 0)\n    low = band_energies.get(\"low\", 0)\n    low_mid = band_energies.get(\"low-mid\", 0)\n    mid = band_energies.get(\"mid\", 0)\n    high_mid = band_energies.get(\"high-mid\", 0)\n    high = band_energies.get(\"high\", 0)\n    air = band_energies.get(\"air\", 0)\n\n    lows = sub + low\n    mids = low_mid + mid + high_mid\n    highs = high + air\n\n    genre = genre.lower()\n\n    if genre in {\"electronic\", \"hiphop\", \"rnb\"}:\n        if lows > 0.75:\n            return \"Low-end is very strong — often genre-typical, but worth a clarity check.\"\n        elif lows > 0.55:\n            return \"Low end is prominent, which is typical for this genre. No action needed unless masking is audible.\"\n        elif mids > 0.5:\n            return \"Mid frequencies dominate — may sound boxy or congested for this genre.\"\n        elif highs > 0.35:\n            return \"Highs are bright — ensure they don’t make the mix feel harsh or distract from the bass foundation.\"\n        else:\n            return \"Spectral balance appears well suited for a bass-driven style.\"\n\n    elif genre in {\"pop\", \"rock\", \"indie\", \"reggae\", \"funk\", \"soul\", \"classic\"}:\n        if lows > 0.6:\n            return \"Low end is strong — may be stylistic, but check for any mud or masking.\"\n        elif lows > 0.45:\n            return \"Low end is moderately elevated — still acceptable depending on artistic intent.\"\n        elif mids > 0.5:\n            return \"Midrange is quite strong — might sound rich, or a bit crowded.\"\n        elif highs > 0.45:\n            return \"Highs are crisp — could add brilliance, or cause sharpness if overdone.\"\n        else:\n            return \"Spectral balance is fairly even and typical for a balanced genre.\"\n\n    elif genre in {\"punk\", \"metal\", \"jazz\", \"country\", \"folk\"}:\n        if lows > 0.50:\n            return \"Low end is elevated — uncommon in this genre, so check for rumble or mud.\"\n        elif mids > 0.55:\n            return \"Midrange is dominant — can sound raw or aggressive, which fits this style.\"\n        elif highs > 0.5:\n            return \"Highs are very pronounced — this can be typical but may fatigue the ear.\"\n        else:\n            return \"Spectral balance looks appropriate for a mid/high-forward genre.\"\n\n    return \"Spectral balance analyzed, but genre could not be matched precisely.\"\n```\n"
  },
  {
    "id": "audio_analysis.py_compute_windowed_rms_db",
    "filename": "audio_analysis.py",
    "function_name": "compute_windowed_rms_db",
    "text": "## Function: compute_windowed_rms_db (audio_analysis.py)\n\n```python\ndef compute_windowed_rms_db(y_mono, sr, window_duration=0.5):\n    window_size = int(sr * window_duration)\n    hop_size = int(window_size / 2)\n\n    rms_blocks = []\n    for i in range(0, len(y_mono) - window_size, hop_size):\n        block = y_mono[i:i + window_size]\n        rms = np.sqrt(np.mean(block ** 2))\n        rms_blocks.append(rms)\n\n    # Now calculate:\n    rms_blocks = np.array(rms_blocks)\n    rms_db_avg = 20 * np.log10(np.mean(rms_blocks) + 1e-9)\n\n    # Loudest 10%\n    sorted_rms = np.sort(rms_blocks)\n    top_10 = sorted_rms[int(len(sorted_rms) * 0.9):]\n    rms_db_peak = 20 * np.log10(np.mean(top_10) + 1e-9)\n\n    return round(rms_db_avg, 2), round(rms_db_peak, 2)\n```\n"
  },
  {
    "id": "audio_analysis.py_detect_transient_strength",
    "filename": "audio_analysis.py",
    "function_name": "detect_transient_strength",
    "text": "## Function: detect_transient_strength (audio_analysis.py)\n\n```python\ndef detect_transient_strength(y, sr):\n    onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n    avg_transient_strength = float(np.mean(onset_env))\n    max_transient_strength = float(np.max(onset_env))\n    return round(avg_transient_strength, 4), round(max_transient_strength, 4)\n```\n"
  },
  {
    "id": "audio_analysis.py_describe_transients",
    "filename": "audio_analysis.py",
    "function_name": "describe_transients",
    "text": "## Function: describe_transients (audio_analysis.py)\n\n```python\ndef describe_transients(avg, max):\n    if avg < 1.5:\n        quality = \"very soft or buried\"\n    elif avg < 3.5:\n        quality = \"balanced\"\n    elif avg < 7:\n        quality = \"punchy and defined\"\n    else:\n        quality = \"sharp or overly spiky\"\n\n    if max > 30:\n        note = \"The track has extremely spiky transients — possibly over-accentuated drums or uncompressed attacks.\"\n    elif max > 15:\n        note = \"Transients are strong and pronounced — mix might feel punchy or aggressive.\"\n    elif max < 5:\n        note = \"Transients appear soft throughout — the mix may lack snap or attack.\"\n    else:\n        note = \"Transient range appears normal for most styles.\"\n\n    return f\"Transients are {quality}. {note}\"\n```\n"
  },
  {
    "id": "audio_analysis.py_generate_peak_issues_description",
    "filename": "audio_analysis.py",
    "function_name": "generate_peak_issues_description",
    "text": "## Function: generate_peak_issues_description (audio_analysis.py)\n\n```python\ndef generate_peak_issues_description(peak_db: float):\n    issues = []\n    explanation_parts = []\n\n    if peak_db > 0.0:\n        issues.append(\"Clipping risk\")\n        explanation_parts.append(\n            \"The track peaks above 0.0 dBFS, which can result in digital clipping. \"\n            \"Even if your DAW meters show 0.0 dB, intersample peaks may exceed this in real-world playback. \"\n            \"Consider using a true peak limiter set to -1.0 dBTP to avoid distortion.\"\n        )\n    elif -0.3 < peak_db <= 0.0:\n        issues.append(\"Near-clipping warning\")\n        explanation_parts.append(\n            \"The track peaks very close to 0.0 dBFS. While it may not clip outright, \"\n            \"there is a risk of intersample peaks causing distortion on some playback systems. \"\n            \"A ceiling of -1.0 dBTP is generally safer.\"\n        )\n    elif peak_db < -5.0:\n        issues.append(\"Low peak level\")\n        explanation_parts.append(\n            \"The track peaks well below typical full-scale levels. \"\n            \"This might indicate improper gain staging and can affect metering or plugin behavior. \"\n            \"Consider raising the level during export to reach closer to 0 dBFS without clipping.\"\n        )\n\n    return issues, \" \".join(explanation_parts)\n```\n"
  },
  {
    "id": "audio_analysis.py_analyze_audio",
    "filename": "audio_analysis.py",
    "function_name": "analyze_audio",
    "text": "## Function: analyze_audio (audio_analysis.py)\n\n```python\ndef analyze_audio(file_path, genre=None):\n    y, sr = librosa.load(file_path, mono=False)\n    print(f\"y shape: {y.shape}, ndim: {y.ndim}\")\n\n    y_mono = librosa.to_mono(y)\n\n    # 🎯 True peak measurement (preserved)\n    peak_amp = np.max(np.abs(y_mono))\n    peak_db = 20 * np.log10(peak_amp + 1e-9)\n\n    # ✅ Normalize to 0 dBFS for consistent analysis\n    y_norm = y_mono / (peak_amp + 1e-9)\n\n    # ✅ Compute loudness + RMS on normalized audio\n    rms_db_avg, rms_db_peak = compute_windowed_rms_db(y_norm, sr)\n    meter = pyln.Meter(sr)\n    loudness = meter.integrated_loudness(y_norm)\n\n    # 🧠 Get peak issue info from unnormalized peak\n    peak_issues, peak_explanation_parts = generate_peak_issues_description(peak_db)\n    peak_explanation_parts = [peak_explanation_parts] if isinstance(peak_explanation_parts,\n                                                                    str) else peak_explanation_parts\n    issues = []\n    pass\n\n    # ✅ warn user if peak is low *and* RMS is still high\n    if peak_db < -3.0 and rms_db_avg > -15.0:\n        peak_issues.append(\"Low peak level without dynamic benefit\")\n        peak_explanation_parts.append(\n            \"The track peaks well below 0 dBFS, but the average loudness remains high. \"\n            \"This suggests the level was lowered without gaining extra dynamic range. \"\n            \"Consider exporting at full scale unless you're preparing for mastering.\"\n        )\n\n    # ✅ Transient strength (on normalized signal)\n    avg_transients, max_transients = detect_transient_strength(y_norm, sr)\n\n    # ✅ Tempo and key detection on normalized audio\n    tempo_arr, _ = librosa.beat.beat_track(y=y_norm, sr=sr)\n    tempo = float(tempo_arr)\n    key = detect_key(y_norm, sr)\n\n    # 🧮 Dynamic range (still meaningful with normalized signal)\n    dynamic_range = peak_db - rms_db_avg  # This reflects actual range even after norm\n\n    # ✅ Stereo width (must use original y to retain L/R difference)\n    width_ratio = 0.0\n    if y.ndim == 1:\n        stereo_width_label = \"narrow\"\n    else:\n        mid = (y[0] + y[1]) / 2\n        side = (y[0] - y[1]) / 2\n        width_ratio = np.mean(np.abs(side)) / (np.mean(np.abs(mid)) + 1e-9)\n\n        if not math.isfinite(width_ratio):\n            width_ratio = 0.0\n            stereo_width_label = \"narrow\"\n        elif width_ratio < 0.25:\n            stereo_width_label = \"narrow\"\n        elif width_ratio < 0.6:\n            stereo_width_label = \"medium\"\n        elif width_ratio < 1.2:\n            stereo_width_label = \"wide\"\n        else:\n            stereo_width_label = \"too wide\"\n\n    # ✅ Spectral analysis (on normalized signal)\n    S = np.abs(librosa.stft(y_norm, n_fft=2048, hop_length=512)) ** 2\n    freqs = librosa.fft_frequencies(sr=sr)\n    total_energy = np.sum(S)\n\n    low_end_mask = freqs <= 150\n    low_end_energy = np.sum(S[low_end_mask])\n    normalized_low_end = low_end_energy / (total_energy + 1e-9)\n    low_end_description = describe_low_end_profile(normalized_low_end, genre=genre)\n\n    if normalized_low_end < 0.1:\n        bass_profile = \"light\"\n    elif normalized_low_end < 0.3:\n        bass_profile = \"balanced\"\n    else:\n        bass_profile = \"bass heavy\"\n\n    band_energies = compute_band_energies(S, freqs)\n    spectral_description = describe_spectral_balance(band_energies, genre=genre)\n\n    return {\n        \"peak_db\": f\"{peak_db:.2f}\",\n        \"rms_db_avg\": round(float(rms_db_avg), 2),\n        \"rms_db_peak\": round(float(rms_db_peak), 2),\n        \"tempo\": f\"{tempo:.2f}\",\n        \"key\": key,\n        \"lufs\": f\"{loudness:.2f}\",\n        \"dynamic_range\": f\"{dynamic_range:.2f}\",\n        \"stereo_width_ratio\": f\"{width_ratio:.2f}\",\n        \"stereo_width\": stereo_width_label,\n        \"low_end_energy_ratio\": f\"{normalized_low_end:.2f}\",\n        \"low_end_description\": low_end_description,\n        \"band_energies\": json.dumps(band_energies),\n        \"spectral_balance_description\": spectral_description,\n        \"peak_issue\": \", \".join(peak_issues) if peak_issues else None,\n        \"peak_issue_explanation\": \" \".join(peak_explanation_parts),\n        \"avg_transient_strength\": avg_transients,\n        \"max_transient_strength\": max_transients,\n        \"transient_description\": describe_transients(avg_transients, max_transients),\n        \"issues\": json.dumps(issues)\n    }\n```\n"
  },
  {
    "id": "analysis_rms_chunks.py_compute_rms_chunks",
    "filename": "analysis_rms_chunks.py",
    "function_name": "compute_rms_chunks",
    "text": "## Function: compute_rms_chunks (analysis_rms_chunks.py)\n\n```python\ndef compute_rms_chunks(file_path, chunk_duration=0.5, json_output_path=None):\n    print(\"🔍 Writing RMS JSON to:\", json_output_path)\n    y, sr = librosa.load(file_path, mono=True)\n    samples_per_chunk = int(sr * chunk_duration)\n    total_chunks = len(y) // samples_per_chunk\n\n    rms_chunks = []\n    for i in range(total_chunks):\n        start = i * samples_per_chunk\n        end = start + samples_per_chunk\n        chunk = y[start:end]\n        if len(chunk) == 0:\n            continue\n        rms = np.sqrt(np.mean(chunk ** 2))\n        rms_db = 20 * np.log10(rms + 1e-9)\n        rms_chunks.append(float(np.round(rms_db, 2)))\n\n    # ✅ Write JSON only if path is provided\n    if json_output_path:\n        json_path = Path(json_output_path)\n        json_path.parent.mkdir(parents=True, exist_ok=True)\n        with open(json_path, \"w\") as f:\n            json.dump(rms_chunks, f)\n\n    return rms_chunks\n```\n"
  },
  {
    "id": "analysis_rms_chunks.py_process_reference_track",
    "filename": "analysis_rms_chunks.py",
    "function_name": "process_reference_track",
    "text": "## Function: process_reference_track (analysis_rms_chunks.py)\n\n```python\ndef process_reference_track(ref_track_path, rms_json_output_dir):\n    # Define output JSON path (e.g., alongside ref track)\n    json_output_path = Path(rms_json_output_dir) / (Path(ref_track_path).stem + \"_rms.json\")\n\n    # Compute RMS chunks using your function\n    rms_chunks = compute_rms_chunks(str(ref_track_path), chunk_duration=0.5, json_output_path=str(json_output_path))\n\n    print(f\"Reference track RMS JSON saved at: {json_output_path}\")\n    return json_output_path\n```\n"
  },
  {
    "id": "sessions.py_get_db",
    "filename": "sessions.py",
    "function_name": "get_db",
    "text": "## Function: get_db (sessions.py)\n\n```python\ndef get_db():\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n```\n"
  },
  {
    "id": "sessions.py_create_or_get_session",
    "filename": "sessions.py",
    "function_name": "create_or_get_session",
    "text": "## Function: create_or_get_session (sessions.py)\n\n```python\n@router.post(\"/\")\ndef create_or_get_session(\n    session_name: str = Body(...),\n    user_id: int = Body(...),\n    db: Session = Depends(get_db)\n):\n    existing = db.query(UserSession).filter_by(session_name=session_name, user_id=user_id).first()\n    if existing:\n        return {\"id\": existing.id, \"session_name\": existing.session_name}\n\n    session_id = str(uuid.uuid4())\n    new_session = UserSession(id=session_id, session_name=session_name, user_id=user_id)\n    db.add(new_session)\n    db.commit()\n    db.refresh(new_session)\n    return {\"id\": new_session.id, \"session_name\": new_session.session_name}\n```\n"
  },
  {
    "id": "sessions.py_list_sessions",
    "filename": "sessions.py",
    "function_name": "list_sessions",
    "text": "## Function: list_sessions (sessions.py)\n\n```python\n@router.get(\"/\")\ndef list_sessions(db: Session = Depends(get_db)):\n    sessions = db.query(UserSession).all()\n    return [{\"id\": s.id, \"session_name\": s.session_name} for s in sessions]\n```\n"
  },
  {
    "id": "sessions.py_get_session",
    "filename": "sessions.py",
    "function_name": "get_session",
    "text": "## Function: get_session (sessions.py)\n\n```python\n@router.get(\"/{id}\")\ndef get_session(id: str, db: Session = Depends(get_db)):\n    session = db.query(UserSession).filter(UserSession.id == id).first()\n    if not session:\n        raise HTTPException(status_code=404, detail=\"Session not found\")\n    return session\n```\n"
  },
  {
    "id": "sessions.py_get_tracks_for_session",
    "filename": "sessions.py",
    "function_name": "get_tracks_for_session",
    "text": "## Function: get_tracks_for_session (sessions.py)\n\n```python\n@router.get(\"/{id}/tracks\")\ndef get_tracks_for_session(\n    id: str,\n    type: str = Query(default=None, description=\"Filter by track type\"),\n    track_name: str = Query(default=None, description=\"Filter by partial name match\"),\n    sort_by: str = Query(default=\"uploaded_at\", enum=[\"uploaded_at\", \"track_name\"]),\n    sort_order: str = Query(default=\"desc\", enum=[\"asc\", \"desc\"]),\n    db: Session = Depends(get_db)\n):\n    try:\n        print(f\"🟡 Looking up session ID: {id}\")\n        session = db.query(UserSession).filter(UserSession.id == id).first()\n        if not session:\n            print(\"⚠️ No session found for that ID.\")\n            raise HTTPException(status_code=404, detail=\"Session not found\")\n\n\n        # ✅ FIX: Use correct ID for feedback query\n        feedback_lookup = {\n            msg.track_id: msg.message\n            for msg in db.query(ChatMessage)\n            .filter(ChatMessage.session_id == id, ChatMessage.sender == \"assistant\", ChatMessage.track_id != None)\n            .order_by(ChatMessage.timestamp.desc())\n            .all()\n        }\n\n        query = db.query(Track).filter(Track.session_id == id)\n\n        # Exclude reference tracks by name\n        query = query.filter(~Track.track_name.ilike('%(Reference)%'))\n\n        if type:\n            query = query.filter(Track.type.ilike(type))\n        if track_name:\n            query = query.filter(Track.track_name.ilike(f\"%{track_name}%\"))\n\n        if sort_by == \"uploaded_at\":\n            query = query.order_by(Track.uploaded_at.desc() if sort_order == \"desc\" else Track.uploaded_at.asc())\n        else:\n            query = query.order_by(Track.track_name.desc() if sort_order == \"desc\" else Track.track_name.asc())\n\n        tracks = query.all()\n\n        result = []\n        for track in tracks:\n            band_energies = {}\n            issues = []\n            analysis_data = None\n\n            if track.analysis:\n                try:\n                    band_energies = json.loads(track.analysis.band_energies or \"{}\")\n                except Exception as e:\n                    print(f\"⚠️ Failed to parse band_energies for track {track.id}: {e}\")\n\n                try:\n                    issues = json.loads(track.analysis.issues or \"[]\")\n                except Exception as e:\n                    print(f\"⚠️ Failed to parse issues for track {track.id}: {e}\")\n\n                analysis_data = {\n                    \"peak_db\": track.analysis.peak_db,\n                    \"rms_db\": track.analysis.rms_db_peak,\n                    \"lufs\": track.analysis.lufs,\n                    \"dynamic_range\": track.analysis.dynamic_range,\n                    \"stereo_width_ratio\": track.analysis.stereo_width_ratio,\n                    \"stereo_width\": track.analysis.stereo_width,\n                    \"key\": track.analysis.key,\n                    \"tempo\": track.analysis.tempo,\n                    \"low_end_energy_ratio\": track.analysis.low_end_energy_ratio,\n                    \"band_energies\": band_energies,\n                    \"issues\": issues,\n                }\n\n            result.append({\n                \"id\": track.id,\n                \"track_name\": track.track_name,\n                \"type\": track.type,\n                \"file_path\": track.file_path,\n                \"uploaded_at\": track.uploaded_at,\n                \"analysis\": analysis_data,\n                \"feedback\": feedback_lookup.get(track.id, \"\")\n            })\n\n        return result\n\n    except Exception as e:\n        print(\"❌ INTERNAL ERROR in /sessions/{id}/tracks:\", e)\n        raise HTTPException(status_code=500, detail=str(e))\n```\n"
  },
  {
    "id": "sessions.py_update_session_name",
    "filename": "sessions.py",
    "function_name": "update_session_name",
    "text": "## Function: update_session_name (sessions.py)\n\n```python\n@router.put(\"/{id}\")\ndef update_session_name(\n    id: str,\n    new_name: str = Form(...),\n    db: Session = Depends(get_db)\n):\n    session = db.query(UserSession).filter(UserSession.id == id).first()\n    if not session:\n        raise HTTPException(status_code=404, detail=\"Session not found\")\n    session.session_name = new_name\n    db.commit()\n    return {\"message\": \"Session updated\", \"session\": session}\n```\n"
  },
  {
    "id": "sessions.py_delete_session",
    "filename": "sessions.py",
    "function_name": "delete_session",
    "text": "## Function: delete_session (sessions.py)\n\n```python\n@router.delete(\"/{id}\")\ndef delete_session(id: str, db: Session = Depends(get_db)):\n    session = db.query(UserSession).filter(UserSession.id == id).first()\n    if not session:\n        raise HTTPException(status_code=404, detail=\"Session not found\")\n\n    # Get all track IDs related to this session\n    track_ids = [t.id for t in db.query(Track.id).filter(Track.session_id == id).all()]\n\n    if track_ids:\n        # Delete chat messages related to these tracks\n        deleted_chats = db.query(ChatMessage).filter(ChatMessage.track_id.in_(track_ids)).delete(synchronize_session=False)\n        print(f\"Deleted {deleted_chats} chat messages linked to session {id}\")\n\n        # Delete analysis results related to these tracks\n        deleted_analysis = db.query(AnalysisResult).filter(AnalysisResult.track_id.in_(track_ids)).delete(synchronize_session=False)\n        print(f\"Deleted {deleted_analysis} analysis results linked to session {id}\")\n\n        # Delete tracks themselves\n        deleted_tracks = db.query(Track).filter(Track.session_id == id).delete(synchronize_session=False)\n        print(f\"Deleted {deleted_tracks} tracks linked to session {id}\")\n\n    # Finally delete the session itself\n    db.delete(session)\n    db.commit()\n\n    return {\"message\": f\"Session and all related tracks, analysis, and chats deleted\"}\n```\n"
  },
  {
    "id": "tracks.py_get_db",
    "filename": "tracks.py",
    "function_name": "get_db",
    "text": "## Function: get_db (tracks.py)\n\n```python\ndef get_db():\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n```\n"
  },
  {
    "id": "tracks.py_get_single_track",
    "filename": "tracks.py",
    "function_name": "get_single_track",
    "text": "## Function: get_single_track (tracks.py)\n\n```python\n@router.get(\"/{track_id}\")\ndef get_single_track(track_id: str, db: Session = Depends(get_db)):\n    track = db.query(Track).filter(Track.id == track_id).first()\n    if not track:\n        raise HTTPException(status_code=404, detail=\"Track not found\")\n\n    return {\n        \"id\": track.id,\n        \"track_name\": track.track_name,\n        \"type\": track.type,\n        \"session_id\": track.session_id,\n        \"file_path\": track.file_path\n    }\n```\n"
  },
  {
    "id": "tracks.py_update_track",
    "filename": "tracks.py",
    "function_name": "update_track",
    "text": "## Function: update_track (tracks.py)\n\n```python\n@router.put(\"/{id}\")\ndef update_track(\n    id: str,\n    track_name: str = Form(...),\n    db: Session = Depends(get_db)\n):\n    track = db.query(Track).filter(Track.id == id).first()\n    if not track:\n        raise HTTPException(status_code=404, detail=\"Track not found\")\n    track.track_name = track_name\n    db.commit()\n    return {\"message\": \"Track updated\", \"track\": track}\n```\n"
  },
  {
    "id": "tracks.py_delete_track",
    "filename": "tracks.py",
    "function_name": "delete_track",
    "text": "## Function: delete_track (tracks.py)\n\n```python\n@router.delete(\"/{id}\")\ndef delete_track(id: str, db: Session = Depends(get_db)):\n    print(\"Deleting track:\", id)\n    track = db.query(Track).filter(Track.id == id).first()\n    if not track:\n        raise HTTPException(status_code=404, detail=\"Track not found\")\n\n    # Delete associated analysis result if any\n    if track.analysis:\n        db.delete(track.analysis)\n\n    # Delete related chat messages\n    deleted_chats = db.query(ChatMessage).filter(ChatMessage.track_id == track.id).delete()\n    print(f\"Deleted {deleted_chats} chat messages for track {track.id}\")\n\n    # Safely delete file if file_path is set and file exists\n    if track.file_path:\n        try:\n            if os.path.exists(track.file_path):\n                os.remove(track.file_path)\n                print(f\"Deleted file: {track.file_path}\")\n            else:\n                print(f\"File path does not exist: {track.file_path}\")\n        except Exception as e:\n            print(f\"Warning: Failed to delete file {track.file_path}: {e}\")\n\n    # Delete track from DB\n    db.delete(track)\n    db.commit()\n\n    return {\"message\": \"Track, analysis, and chat messages deleted\"}\n```\n"
  },
  {
    "id": "upload.py_upload_audio",
    "filename": "upload.py",
    "function_name": "upload_audio",
    "text": "## Function: upload_audio (upload.py)\n\n```python\n@router.post(\"/\")\ndef upload_audio(\n    file: UploadFile = File(...),\n    ref_file: Optional[UploadFile] = File(None),\n    session_id: str = Form(...),\n    session_name: Optional[str] = Form(default=\"Untitled Session\"),\n    track_name: Optional[str] = Form(default=None),\n    type: str = Form(...),\n    genre: str = Form(...),\n    subgenre: Optional[str] = Form(default=None),\n    feedback_profile: str = Form(...),\n):\n    # Normalize inputs\n    session_id = normalize_session_name(session_id)\n    session_name = normalize_session_name(session_name)\n    type = type.strip().lower()\n    genre = normalize_genre(genre)\n    subgenre = normalize_subgenre(subgenre) if subgenre else \"\"\n    feedback_profile = normalize_profile(feedback_profile)\n    group_id = str(uuid.uuid4())\n\n    try:\n        print(\"Incoming upload:\", {\n            \"session_id\": session_id,\n            \"track_name\": track_name,\n            \"type\": type,\n            \"genre\": genre,\n            \"subgenre\": subgenre,\n            \"feedback_profile\": feedback_profile\n        })\n\n        # Save original track\n        ext = os.path.splitext(file.filename)[1]\n        timestamped_name = f\"{int(time.time())}_{file.filename}\"\n        file_location = os.path.join(UPLOAD_FOLDER, timestamped_name)\n        with open(file_location, \"wb\") as buffer:\n            shutil.copyfileobj(file.file, buffer)\n\n        # Save reference track if uploaded\n        ref_file_location = None\n        ref_analysis = None\n        ref_timestamped_name = None\n\n        if ref_file and ref_file.filename:\n            ref_ext = os.path.splitext(ref_file.filename)[1]\n            ref_timestamped_name = f\"{int(time.time())}_ref_{ref_file.filename}\"\n            ref_file_location = os.path.join(UPLOAD_FOLDER, ref_timestamped_name)\n            with open(ref_file_location, \"wb\") as buffer:\n                shutil.copyfileobj(ref_file.file, buffer)\n\n            ref_analysis = analyze_audio(ref_file_location, genre=genre)\n        else:\n            ref_file_location = None\n            ref_analysis = None\n\n        print(\"Passing ref_analysis to prompt:\", ref_analysis is not None)\n\n            # Optional: delete reference file after analysis if you don't want to keep it on disk\n            # os.remove(ref_file_location)\n\n        BASE_DIR = Path(__file__).resolve().parents[3]\n        rms_filename = f\"{timestamped_name}_rms.json\"\n        rms_output_path = BASE_DIR / \"frontend-html\" / \"static\" / \"analysis\" / rms_filename\n        compute_rms_chunks(file_location, json_output_path=str(rms_output_path))\n        print(\"✅ RMS saved to:\", rms_output_path)\n\n        # Analyze original track\n        analysis = analyze_audio(file_location, genre=genre)\n\n        # Database operations\n        db = SessionLocal()\n\n        # Cleanup old main track files for the same session before saving new upload\n        old_tracks = db.query(Track).filter(Track.session_id == session_id).all()\n        for old_track in old_tracks:\n            # Delete audio file\n            try:\n                if old_track.file_path and os.path.exists(old_track.file_path):\n                    os.remove(old_track.file_path)\n                    print(f\"Deleted old main track file: {old_track.file_path}\")\n            except Exception as e:\n                print(f\"Error deleting old main track file {old_track.file_path}: {e}\")\n\n        existing_session = db.query(UserSession).filter(UserSession.id == session_id).first()\n        if not existing_session:\n            new_session = UserSession(id=session_id, user_id=1, session_name=session_name)\n            db.add(new_session)\n            db.commit()\n\n        filename_without_ext = os.path.splitext(file.filename)[0]\n        safe_name = safe_track_name(filename_without_ext, file.filename)\n        track_name = track_name or safe_name\n\n        track = Track(\n            session_id=session_id,\n            track_name=track_name,\n            file_path=file_location,\n            type=type.lower(),\n            upload_group_id = group_id\n        )\n        db.add(track)\n        db.commit()\n        db.refresh(track)\n\n        result = AnalysisResult(track_id=track.id, **analysis)\n        db.add(result)\n        db.commit()\n\n        print(\"Analysis data for main track:\", analysis)\n        if ref_file_location:\n            # Analyze reference track first\n            ref_analysis = analyze_audio(ref_file_location, genre=genre)\n            print(\"Reference track analysis data:\", ref_analysis)\n\n            # Create the reference track in DB with same upload_group_id\n            ref_track_name = f\"{track_name} (Reference)\"\n            ref_track = Track(\n                session_id=session_id,\n                track_name=ref_track_name,\n                file_path=ref_file_location,\n                type=\"reference\",\n                upload_group_id=group_id  # assign the same group id here!\n            )\n            db.add(ref_track)\n            db.commit()\n            db.refresh(ref_track)\n\n            # Save analysis result for reference track\n            ref_result = AnalysisResult(track_id=ref_track.id, **ref_analysis)\n            db.add(ref_result)\n            db.commit()\n        else:\n            ref_analysis = None\n\n        print(\"Passing ref_analysis to prompt:\", ref_analysis is not None)\n\n        # Generate GPT feedback with both original and ref analysis\n        prompt = generate_feedback_prompt(\n            genre=genre,\n            subgenre=subgenre,\n            type=type,\n            analysis_data=analysis,\n            feedback_profile=feedback_profile,\n            ref_analysis_data=ref_analysis  # pass ref analysis here\n        )\n\n        feedback = generate_feedback_response(prompt)\n\n        chat = ChatMessage(\n            session_id=session_id,\n            track_id=track.id,\n            sender=\"assistant\",\n            message=feedback,\n            feedback_profile=feedback_profile\n        )\n        db.add(chat)\n        db.commit()\n        db.close()\n\n        return {\n            \"track_name\": track_name,\n            \"genre\": genre,\n            \"subgenre\": subgenre,\n            \"type\": type,\n            \"analysis\": analysis,\n            \"ref_analysis\": ref_analysis,  # included in response\n            \"feedback\": feedback,\n            \"track_path\": f\"/uploads/{timestamped_name}\",\n            \"ref_track_path\": f\"/uploads/{ref_timestamped_name}\" if ref_timestamped_name else None,\n            \"rms_path\": f\"/static/analysis/{rms_filename}\"\n        }\n\n\n    except Exception as e:\n        import traceback\n        traceback.print_exc()  # prints full stack trace in console\n        print(\"UPLOAD ERROR:\", e)\n        return JSONResponse(status_code=500, content={\"detail\": str(e)})\n```\n"
  },
  {
    "id": "export.py_get_db",
    "filename": "export.py",
    "function_name": "get_db",
    "text": "## Function: get_db (export.py)\n\n```python\ndef get_db():\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n```\n"
  },
  {
    "id": "export.py_get_feedback_text",
    "filename": "export.py",
    "function_name": "get_feedback_text",
    "text": "## Function: get_feedback_text (export.py)\n\n```python\ndef get_feedback_text(session_id: str, track_id: str, db: Session) -> str:\n    messages = (\n        db.query(ChatMessage)\n        .filter_by(session_id=session_id, track_id=track_id, sender='assistant')\n        .order_by(ChatMessage.timestamp)\n        .all()\n    )\n    return \"\\n\\n\".join(msg.message for msg in messages)\n```\n"
  },
  {
    "id": "export.py_generate_preset_text_from_feedback",
    "filename": "export.py",
    "function_name": "generate_preset_text_from_feedback",
    "text": "## Function: generate_preset_text_from_feedback (export.py)\n\n```python\ndef generate_preset_text_from_feedback(feedback_text: str) -> str:\n    prompt = f\"\"\"\n\nHere is the AI feedback you generated previously:\n\n\\\"\\\"\\\"\n{feedback_text}\n\\\"\\\"\\\"\n\nYou are generating a report for ZoundZcope AI.\n\nPlease output the content exactly as follows, with these section headings and formatting:\n\n---\n\nZoundZcope AI\n\nMixing & Mastering Feedback and Presets Report\n\nAI Feedback:\n\n- ISSUE:\n  [Describe the issue clearly in a few sentences.]\n\n- IMPROVEMENT:\n  [Describe the suggested improvement clearly.]\n\n(Repeat multiple ISSUE and IMPROVEMENT pairs as needed.)\n\nRecommended Ableton Preset Parameters:\n\nEQ8:\n- Band 1: [parameters like frequency, gain, Q, shelf/bell + a brief note in brackets]\n- Band 2: [parameters like frequency, gain, Q, shelf/bell + a brief note in brackets]\n(Repeat for more bands if needed)\n\nCompressor:\n- Threshold: [value]\n- Ratio: [value]\n- Attack: [value]\n- Release: [value]\n- Makeup Gain: [value]\n\nTransient Shaper:\n- [Parameters]: [value]\n(Repeat for more parameters if needed)\n\nMultiband Dynamics:\n- [Parameters]: [value]\n(Repeat for more parameters if needed)\n\nLimiter:\n- [Parameters]: [value]\n(Repeat for more parameters if needed)\n\nUtils:\n- [Parameters]: [value]\n(Repeat for more parameters if needed)\n\n\n(Include plugins relevant to the feedback. Provide brief notes in parentheses explaining the purpose of adjustments.)\n\n---\n\nNotes:\n\n- Use exactly the headings and labels shown above.\n- Keep \"ZoundZcope AI\" as the main title.\n- Use \"Mixing & Mastering Feedback and Presets Report\" as the subtitle.\n- Use \"AI Feedback:\" and \"Recommended Ableton Preset Parameters:\" as section headers.\n- Use uppercase \"ISSUE:\" and \"IMPROVEMENT:\" labels.\n- List plugin names like \"EQ8:\" and \"Compressor:\" exactly as shown.\n- Use simple bullet points with dashes (-) for parameters.\n- Do NOT include any markdown formatting, HTML tags, or extra decorations.\n- Only output plain text with line breaks as shown.\n\nGenerate the content now:\n\"\"\"\n    return generate_feedback_response(prompt)\n```\n"
  },
  {
    "id": "export.py_draw_wrapped_text",
    "filename": "export.py",
    "function_name": "draw_wrapped_text",
    "text": "## Function: draw_wrapped_text (export.py)\n\n```python\ndef draw_wrapped_text(p, text, x, y, max_width, line_height=14):\n    lines = simpleSplit(text, \"Helvetica\", 10, max_width)\n    for line in lines:\n        if y < 50:\n            p.showPage()\n            y = letter[1] - 40\n            p.setFont(\"Helvetica\", 10)\n        p.drawString(x, y, line)\n        y -= line_height\n    return y\n```\n"
  },
  {
    "id": "export.py_create_pdf",
    "filename": "export.py",
    "function_name": "create_pdf",
    "text": "## Function: create_pdf (export.py)\n\n```python\ndef create_pdf(full_report_text: str) -> BytesIO:\n    buffer = BytesIO()\n    doc = SimpleDocTemplate(buffer, pagesize=letter,\n                            rightMargin=40, leftMargin=40,\n                            topMargin=40, bottomMargin=40)\n\n    # Define styles\n    styles = getSampleStyleSheet()\n\n    company_title_style = ParagraphStyle(\n        'CompanyTitle',\n        fontName='Helvetica-Bold',\n        fontSize=24,\n        leading=28,\n        alignment=TA_CENTER,\n        spaceAfter=20\n    )\n\n    subheadline_style = ParagraphStyle(\n        'Subheadline',\n        fontName='Helvetica-Bold',\n        fontSize=16,\n        leading=20,\n        alignment=TA_CENTER,\n        spaceAfter=18\n    )\n\n    section_header_style = ParagraphStyle(\n        'SectionHeader',\n        fontName='Helvetica-Bold',\n        fontSize=12,\n        leading=14,\n        spaceAfter=10\n    )\n\n    uppercase_bold_style = ParagraphStyle(\n        'UppercaseBold',\n        fontName='Helvetica-Bold',\n        fontSize=10,\n        leading=14,\n        spaceAfter=6\n    )\n\n    normal_style = ParagraphStyle(\n        'Normal',\n        fontName='Helvetica',\n        fontSize=10,\n        leading=14,\n        spaceAfter=6\n    )\n\n    plugin_name_style = ParagraphStyle(\n        'PluginName',\n        fontName='Helvetica-Bold',\n        fontSize=10,\n        leading=14,\n        spaceAfter=2\n    )\n\n    plugin_data_style = ParagraphStyle(\n        'PluginData',\n        fontName='Helvetica',\n        fontSize=10,\n        leading=14,\n        leftIndent=12,\n        spaceAfter=2\n    )\n\n    elements = []\n\n    # Split lines\n    lines = [line.strip() for line in full_report_text.strip().split(\"\\n\")]\n\n    # For grouping bullet points (plugin parameters)\n    bullet_group = []\n\n    def flush_bullet_group():\n        nonlocal bullet_group\n        if bullet_group:\n            bullet_items = [ListItem(Paragraph(item, plugin_data_style)) for item in bullet_group]\n            elements.append(ListFlowable(bullet_items, bulletType='bullet'))\n            bullet_group = []\n\n    for line in lines:\n        if not line:\n            flush_bullet_group()\n            elements.append(Spacer(1, 8))\n            continue\n\n        # Company title\n        if line.lower().startswith(\"zoundzcope ai\"):\n            flush_bullet_group()\n            elements.append(Paragraph(line, company_title_style))\n            continue\n\n        # Subheadline\n        if \"feedback and presets report\" in line.lower():\n            flush_bullet_group()\n            elements.append(Paragraph(line, subheadline_style))\n            continue\n\n        # Section headers\n        if line in [\"AI Feedback:\", \"Recommended Ableton Preset Parameters:\"]:\n            flush_bullet_group()\n            elements.append(Paragraph(line, section_header_style))\n            continue\n\n        # Uppercase ISSUE / IMPROVEMENT labels\n        if line.startswith(\"- ISSUE:\") or line.startswith(\"- IMPROVEMENT:\"):\n            flush_bullet_group()\n            label, _, rest = line.partition(\":\")\n            label = label.replace(\"- \", \"\").upper() + \":\"\n            elements.append(Paragraph(label, uppercase_bold_style))\n            if rest.strip():\n                elements.append(Paragraph(rest.strip(), normal_style))\n            continue\n\n        # Plugin names (bold)\n        if any(line.startswith(plugin) for plugin in [\"EQ8:\", \"Compressor:\", \"Glue Compressor:\", \"Limiter:\", \"Multiband Dynamics:\", \"Utils:\"]):\n            flush_bullet_group()\n            elements.append(Paragraph(line, plugin_name_style))\n            continue\n\n        # Plugin data bullet points (collect in group)\n        if line.startswith(\"- \"):\n            bullet_group.append(line[2:].strip())\n            continue\n\n        # Default normal text\n        flush_bullet_group()\n        elements.append(Paragraph(line, normal_style))\n\n    # Flush leftover bullets at the end\n    flush_bullet_group()\n\n    doc.build(elements)\n    buffer.seek(0)\n    return buffer\n```\n"
  },
  {
    "id": "export.py_export_feedback_presets",
    "filename": "export.py",
    "function_name": "export_feedback_presets",
    "text": "## Function: export_feedback_presets (export.py)\n\n```python\n@router.get(\"/export-feedback-presets\")\ndef export_feedback_presets(\n    session_id: str = Query(...),\n    track_id: str = Query(...),\n    db: Session = Depends(get_db)\n):\n    print(f\"Export request for session {session_id}, track {track_id}\")\n\n    # Fetch the track object\n    track = db.query(Track).filter(Track.id == track_id).first()\n    if not track:\n        raise HTTPException(status_code=404, detail=\"Track not found\")\n\n    # Detect if this is a reference track by name or however you identify it\n    if \"(Reference)\" in (track.track_name or \"\"):\n        # Find main track(s) for this session excluding reference tracks\n        main_track = (\n            db.query(Track)\n            .filter(\n                Track.session_id == session_id,\n                ~Track.track_name.contains(\"(Reference)\"),\n            )\n            .order_by(Track.uploaded_at.desc())\n            .first()\n        )\n\n        if not main_track:\n            raise HTTPException(\n                status_code=404,\n                detail=\"No main track found for this session to export feedback\",\n            )\n        print(f\"Reference track detected, switching export to main track {main_track.id}\")\n        track_id = main_track.id\n\n    # Now fetch feedback messages for the track_id (could be original or switched)\n    messages = (\n        db.query(ChatMessage)\n        .filter_by(session_id=session_id, track_id=track_id, sender='assistant')\n        .order_by(ChatMessage.timestamp)\n        .all()\n    )\n\n    if not messages:\n        raise HTTPException(status_code=404, detail=\"No feedback found for this session and track\")\n\n    feedback_text = \"\\n\\n\".join(msg.message for msg in messages)\n\n    full_report = generate_preset_text_from_feedback(feedback_text)\n    pdf_buffer = create_pdf(full_report)\n\n    return StreamingResponse(\n        pdf_buffer,\n        media_type=\"application/pdf\",\n        headers={\n            \"Content-Disposition\": f\"attachment; filename=feedback_presets_{session_id}_{track_id}.pdf\"\n        }\n    )\n```\n"
  },
  {
    "id": "export.py_flush_bullet_group",
    "filename": "export.py",
    "function_name": "flush_bullet_group",
    "text": "## Function: flush_bullet_group (export.py)\n\n```python\n    def flush_bullet_group():\n        nonlocal bullet_group\n        if bullet_group:\n            bullet_items = [ListItem(Paragraph(item, plugin_data_style)) for item in bullet_group]\n            elements.append(ListFlowable(bullet_items, bulletType='bullet'))\n            bullet_group = []\n```\n"
  },
  {
    "id": "chat.py_get_db",
    "filename": "chat.py",
    "function_name": "get_db",
    "text": "## Function: get_db (chat.py)\n\n```python\ndef get_db():\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n```\n"
  },
  {
    "id": "chat.py_get_feedback",
    "filename": "chat.py",
    "function_name": "get_feedback",
    "text": "## Function: get_feedback (chat.py)\n\n```python\n@router.get(\"/generate_feedback\")\ndef get_feedback(\n    track_id: str = Form(...),\n    session_id: str = Form(...),\n    genre: str = Form(...),\n    type: str = Form(...),\n    feedback_profile: str = Form(...),\n    db: Session = Depends(get_db)\n):\n    \"\"\"\n    Handle a request to generate AI mixing/mastering feedback for a given audio track.\n\n    This function normalizes user inputs, fetches audio analysis data, builds\n    an AI prompt, sends it for feedback generation, saves the feedback in the\n    database, and returns it to the client.\n\n    Parameters:\n        track_id (str): Unique identifier of the audio track.\n        session_id (str): Current user session identifier.\n        genre (str): Genre of the track, used to tailor feedback.\n        type (str): Feedback type ('mixdown', 'mastering', 'master review').\n        feedback_profile (str): Detail level ('simple', 'detailed', 'pro').\n        db (Session): Database session for querying track data.\n\n    Returns:\n        dict: JSON response containing AI feedback text, or error message if analysis not found.\n    \"\"\"\n\n    genre = normalize_genre(genre)\n    type = normalize_type(type)\n    feedback_profile = normalize_profile(feedback_profile)\n\n    # Fetch track and analysis\n    track = db.query(Track).filter(Track.id == track_id).first()\n    if not track or not track.analysis:\n        return {\"error\": \"Track analysis not found\"}\n\n    analysis = {\n        \"peak_db\": track.analysis.peak_db,\n        \"rms_db\": track.analysis.rms_db,\n        \"lufs\": track.analysis.lufs,\n        \"dynamic_range\": track.analysis.dynamic_range,\n        \"stereo_width\": track.analysis.stereo_width,\n        \"key\": track.analysis.key,\n        \"tempo\": track.analysis.tempo,\n        \"low_end_energy_ratio\": track.analysis.low_end_energy_ratio,\n        \"bass_profile\": track.analysis.bass_profile,\n        \"band_energies\": json.loads(track.analysis.band_energies),\n        \"issues\": json.loads(track.analysis.issues),\n    }\n\n    prompt = generate_feedback_prompt(genre, type, analysis, feedback_profile)\n    feedback = generate_feedback_response(prompt)\n\n    chat = ChatMessage(\n        session_id=session_id,\n        track_id=track.id,\n        sender=\"assistant\",\n        message=feedback,\n        feedback_profile=feedback_profile\n    )\n    db.add(chat)\n    db.commit()\n\n    return {\"feedback\": feedback}\n```\n"
  },
  {
    "id": "chat.py_ask_followup",
    "filename": "chat.py",
    "function_name": "ask_followup",
    "text": "## Function: ask_followup (chat.py)\n\n```python\n@router.post(\"/ask-followup\")\ndef ask_followup(req: FollowUpRequest, db: Session = Depends(get_db)):\n    \"\"\"\n        Fetches the main track and optional reference track analysis from the database.\n        Retrieves the previous follow-up summary if available to provide context for the AI prompt.\n\n        Parameters:\n            req (FollowUpRequest): The follow-up request containing session, track, and follow-up group info.\n            db (Session): Database session for querying data.\n\n        Returns:\n            tuple: (main_track, ref_analysis, summary_text)\n                main_track: The primary Track object or None if not found.\n                ref_analysis: Dict of reference track analysis data or None.\n                summary_text: Previous follow-up summary string or empty string.\n        \"\"\"\n\n    profile = normalize_profile(req.feedback_profile)\n    user_question = sanitize_user_question(req.user_question)\n\n    # 1. Fetch main track\n    main_track = db.query(Track).filter(Track.id == req.track_id).first()\n    if not main_track:\n        raise HTTPException(status_code=404, detail=\"Main track not found\")\n\n    # 2. Fetch reference track by upload_group_id\n    ref_track = (\n        db.query(Track)\n        .filter(\n            Track.upload_group_id == main_track.upload_group_id,\n            Track.type == \"reference\"\n        )\n        .order_by(Track.uploaded_at.desc())\n        .first()\n    )\n\n    ref_analysis = None\n    if ref_track and ref_track.analysis:\n        ref_analysis = {\n            \"peak_db\": ref_track.analysis.peak_db,\n            \"rms_db_peak\": ref_track.analysis.rms_db_peak,\n            \"lufs\": ref_track.analysis.lufs,\n            \"transient_description\": ref_track.analysis.transient_description,\n            \"spectral_balance_description\": ref_track.analysis.spectral_balance_description,\n            \"dynamic_range\": ref_track.analysis.dynamic_range,\n            \"stereo_width\": ref_track.analysis.stereo_width,\n            \"low_end_description\": ref_track.analysis.low_end_description,\n            # add other needed fields...\n        }\n\n    # 3. Retrieve previous follow-up summary if applicable\n    summary_text = \"\"\n    if req.followup_group > 0:\n        summary_msg = (\n            db.query(ChatMessage)\n            .filter_by(\n                session_id=req.session_id,\n                track_id=req.track_id,\n                followup_group=req.followup_group - 1,\n                sender=\"assistant\",\n                feedback_profile=\"summary\"\n            )\n            .order_by(ChatMessage.timestamp.desc())\n            .first()\n        )\n        print(f\"Previous summary message for group {req.followup_group - 1}: {summary_msg.message if summary_msg else 'None'}\")\n        if summary_msg:\n            summary_text = summary_msg.message\n\n    # 3. Build prompt including ref_analysis data and summary\n    prompt = build_followup_prompt(\n        analysis_text=req.analysis_text,\n        feedback_text=req.feedback_text,\n        user_question=user_question,\n        thread_summary=summary_text,\n        ref_analysis_data=req.ref_analysis_data\n    )\n\n    try:\n        ai_response = generate_feedback_response(prompt)\n        print(\"GPT response:\", ai_response)\n    except Exception as e:\n        print(\"❌ GPT call failed:\", e)\n        raise HTTPException(status_code=500, detail=\"AI follow-up failed\")\n\n    # Save user message\n    user_msg = ChatMessage(\n        session_id=req.session_id,\n        track_id=req.track_id,\n        sender=\"user\",\n        message=user_question,\n        feedback_profile=profile,\n        followup_group=req.followup_group\n    )\n    db.add(user_msg)\n\n    # Save AI assistant response\n    assistant_msg = ChatMessage(\n        session_id=req.session_id,\n        track_id=req.track_id,\n        sender=\"assistant\",\n        message=ai_response,\n        feedback_profile=profile,\n        followup_group=req.followup_group\n    )\n    db.add(assistant_msg)\n    db.commit()\n\n\n    # --- Automatic summary creation after 4 user follow-ups ---\n    user_msgs_count = (\n        db.query(ChatMessage)\n        .filter_by(\n            session_id=req.session_id,\n            track_id=req.track_id,\n            followup_group=req.followup_group,\n            sender=\"user\"\n        )\n        .count()\n    )\n\n    response_data = {\"answer\": ai_response}\n\n    existing_summary = (\n        db.query(ChatMessage)\n        .filter_by(\n            session_id=req.session_id,\n            track_id=req.track_id,\n            followup_group=req.followup_group,\n            sender=\"assistant\",\n            feedback_profile=\"summary\"\n        )\n        .first()\n    )\n\n    if user_msgs_count >= 2 and not existing_summary:\n        # Fetch all messages in this group (user + assistant)\n        msgs = (\n            db.query(ChatMessage)\n            .filter_by(\n                session_id=req.session_id,\n                track_id=req.track_id,\n                followup_group=req.followup_group,\n            )\n            .order_by(ChatMessage.timestamp)\n            .all()\n        )\n\n        conversation = \"\\n\".join(\n            f\"{'User' if msg.sender == 'user' else 'Assistant'}: {msg.message}\"\n            for msg in msgs\n        )\n\n        summary_prompt = f\"\"\"\nSummarize this follow-up thread (up to 4 user questions and assistant responses) into a concise overall improvement strategy:\n\n{conversation}\n\"\"\"\n\n        print(f\"Generating summary for followup_group {req.followup_group} with conversation:\\n{conversation}\")\n\n        summary_text = generate_feedback_response(summary_prompt)\n\n        print(f\"✅ Auto summary saved for followup_group {req.followup_group}\")\n        print(f\"Summary content:\\n{summary_text}\\n{'-'*40}\")\n\n        summary_msg = ChatMessage(\n            session_id=req.session_id,\n            track_id=req.track_id,\n            sender=\"assistant\",\n            message=summary_text,\n            feedback_profile=\"summary\",\n            followup_group=req.followup_group\n        )\n        db.add(summary_msg)\n        db.commit()\n\n        response_data[\"summary_created\"] = True\n\n    return response_data\n```\n"
  },
  {
    "id": "chat.py_get_messages_for_track",
    "filename": "chat.py",
    "function_name": "get_messages_for_track",
    "text": "## Function: get_messages_for_track (chat.py)\n\n```python\n@router.get(\"/tracks/{track_id}/messages\")\ndef get_messages_for_track(track_id: str, db: Session = Depends(get_db)):\n    track = db.query(Track).filter_by(id=track_id).first()\n    if not track:\n        raise HTTPException(status_code=404, detail=\"Track not found\")\n\n    messages = (\n        db.query(ChatMessage)\n        .filter(ChatMessage.track_id == track_id)\n        .order_by(ChatMessage.timestamp.asc())\n        .all()\n    )\n\n    print(f\"DEBUG: Found {len(messages)} messages for track_id={track_id}\")\n    for msg in messages:\n        print(f\"DEBUG: message id={msg.id} content={msg.message[:30]}\")\n\n    return [\n        {\n            \"sender\": msg.sender,\n            \"message\": msg.message,\n            \"feedback_profile\": msg.feedback_profile,\n            \"type\": track.type,\n            \"track_name\": track.track_name\n        }\n        for msg in messages\n    ]\n```\n"
  },
  {
    "id": "chat.py_summarize_thread",
    "filename": "chat.py",
    "function_name": "summarize_thread",
    "text": "## Function: summarize_thread (chat.py)\n\n```python\n@router.post(\"/summarize-thread\")\ndef summarize_thread(req: SummarizeRequest, db: Session = Depends(get_db)):\n    \"\"\"\n        Generate a summary of a follow-up conversation thread.\n\n        Retrieves chat messages for a given session, track, and follow-up group,\n        then uses AI to summarize the thread into a concise improvement strategy.\n\n        Parameters:\n            req (SummarizeRequest): Contains session_id, track_id, and followup_group.\n            db (Session): Database session for querying chat messages.\n\n        Returns:\n            dict: A JSON response with the AI-generated summary or a message if\n                  no follow-up messages are found.\n        \"\"\"\n    print(f\"Summarize request: session_id={req.session_id}, track_id={req.track_id}, group={req.followup_group}\")\n    messages = (\n        db.query(ChatMessage)\n        .filter_by(session_id=req.session_id, track_id=req.track_id, followup_group=req.followup_group)\n        .order_by(ChatMessage.timestamp)\n        .all()\n    )\n    print(f\"Found {len(messages)} messages\")\n    # Count only user messages as \"follow-up\" messages\n    user_msgs = [msg for msg in messages if msg.sender == \"user\"]\n\n    if not user_msgs:\n        return {\"summary\": \"No follow-up messages found for this thread to summarize.\"}\n\n    thread = []\n    for msg in messages:\n        if msg.sender == \"user\":\n            thread.append({\"role\": \"user\", \"content\": msg.message})\n        else:\n            thread.append({\"role\": \"assistant\", \"content\": msg.message})\n\n    conversation = \"\\n\".join([f\"{m['role'].capitalize()}: {m['content']}\" for m in thread])\n    print(f\"Conversation for summarization:\\n{conversation}\")\n\n    if not conversation.strip():\n        return {\"summary\": \"No follow-up messages found for this thread to summarize.\"}\n\n    prompt = f\"\"\"\nSummarize this follow-up thread (5 user questions with assistant responses) into a concise overall improvement strategy:\n\n{conversation}\n\"\"\"\n\n    summary = generate_feedback_response(prompt)\n    return {\"summary\": summary}\n```\n"
  },
  {
    "id": "chat.py_test",
    "filename": "chat.py",
    "function_name": "test",
    "text": "## Function: test (chat.py)\n\n```python\n@router.get(\"/test\")\ndef test():\n    return {\"message\": \"Chat router works\"}\n```\n"
  }
]